# Streamlit Dashboard - Display Charts from ProteinData.ipynb
# No model loading - just visualizations

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import plotly.express as px
import plotly.graph_objects as go
from PIL import Image, ImageStat
import warnings
import joblib
import io
import cv2
from sklearn.cluster import KMeans
from skimage.color import rgb2gray
from skimage.feature import hog, local_binary_pattern
from skimage.filters import sobel
from matplotlib.colors import rgb_to_hsv

warnings.filterwarnings('ignore')

# Page configuration
st.set_page_config(
    page_title="Protein Sales Analysis Dashboard",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# GUARANTEED INITIAL RENDER
# ============================================================================
st.title("üìä Protein Product Sales Analysis Dashboard")
st.markdown("---")
st.write("**Visualization Dashboard** - Charts and analysis from ProteinData.ipynb")

# ============================================================================
# LOAD DATA AND MODEL
# ============================================================================
def find_project_root(start_path=None):
    """Find the MainProject directory by walking up from start_path.
    Works in both local development and deployed environments (Streamlit Cloud).
    """
    if start_path is None:
        # Try to get the script's directory, fallback to current working directory
        try:
            start_path = Path(__file__).parent.resolve()
        except NameError:
            # __file__ not available (e.g., in some deployment environments like Streamlit Cloud)
            start_path = Path.cwd()
    else:
        start_path = Path(start_path).resolve()
    
    # First, check if we're already in a directory with ml_outputs
    # This is the most reliable indicator and works in deployment
    test_path = start_path / "ml_outputs"
    if test_path.exists():
        return start_path
    
    # Check parent directories for ml_outputs (more reliable than directory name)
    current = start_path
    while current != current.parent:
        test_path = current / "ml_outputs"
        if test_path.exists():
            return current
        current = current.parent
    
    # Fallback: Check if directory is named "MainProject"
    current = start_path
    while current != current.parent:
        if current.name == "MainProject":
            return current
        current = current.parent
    
    # Final fallback: return the original start_path
    return start_path

# Get the MainProject root directory
PROJECT_DIR = find_project_root()
OUTPUT_DIR = PROJECT_DIR / "ml_outputs"

@st.cache_data
def load_data():
    """Load feature table data"""
    feature_file = OUTPUT_DIR / 'feature_table_with_metadata.csv'
    
    # Check if file exists first
    if not feature_file.exists():
        # Provide helpful debugging information
        debug_info = f"""
**File not found:** `{feature_file}`

**Debugging Information:**
- PROJECT_DIR: `{PROJECT_DIR}`
- OUTPUT_DIR: `{OUTPUT_DIR}`
- File path: `{feature_file}`
- OUTPUT_DIR exists: `{OUTPUT_DIR.exists()}`
- OUTPUT_DIR is directory: `{OUTPUT_DIR.is_dir() if OUTPUT_DIR.exists() else 'N/A'}`

**Solution:**
1. Ensure `feature_table_with_metadata.csv` exists in the `ml_outputs/` directory
2. Run `ProteinData.ipynb` to generate the file
3. Verify the file is committed to your repository (for deployed apps)
"""
        return None, False, debug_info
    
    try:
        df = pd.read_csv(feature_file)
        if df.empty:
            return None, False, "File exists but is empty"
        return df, True, None
    except Exception as e:
        return None, False, f"Error reading file: {str(e)}"

@st.cache_resource
def load_classification_model():
    """Load classification model and scaler"""
    model_file = OUTPUT_DIR / 'rf_clf.pkl'
    scaler_file = OUTPUT_DIR / 'scaler.pkl'
    
    # Check if files exist first
    missing_files = []
    if not model_file.exists():
        missing_files.append(f"rf_clf.pkl (path: {model_file})")
    if not scaler_file.exists():
        missing_files.append(f"scaler.pkl (path: {scaler_file})")
    
    if missing_files:
        debug_info = f"""
**Model files not found:**

Missing files:
{chr(10).join(f'- {f}' for f in missing_files)}

**Debugging Information:**
- PROJECT_DIR: `{PROJECT_DIR}`
- OUTPUT_DIR: `{OUTPUT_DIR}`
- OUTPUT_DIR exists: `{OUTPUT_DIR.exists()}`
- OUTPUT_DIR is directory: `{OUTPUT_DIR.is_dir() if OUTPUT_DIR.exists() else 'N/A'}`
- Model file exists: `{model_file.exists()}`
- Scaler file exists: `{scaler_file.exists()}`

**Solution:**
1. Run `ProteinData.ipynb` to generate the model files
2. Or run `save_models_as_pkl.py` to convert models from the notebook
3. Verify the files are committed to your repository (for deployed apps)
4. Check that files are in: `{OUTPUT_DIR}`
"""
        return None, None, False, debug_info
    
    try:
        model = joblib.load(model_file)
        scaler = joblib.load(scaler_file)
        return model, scaler, True, None
    except Exception as e:
        return None, None, False, f"Error loading model files: {str(e)}"

# Load data and model
data, data_loaded, data_error = load_data()
clf_model, scaler, model_loaded, model_error = load_classification_model()

# ============================================================================
# SIDEBAR NAVIGATION
# ============================================================================
st.sidebar.title("üìä Navigation")
st.sidebar.markdown("---")

page = st.sidebar.radio(
    "Select Page",
    ["üè† Home", "üìà Saved Charts", "üìä Interactive Charts", "üìã Data Explorer", "üß™ Testing"]
)

# Show data and model status
st.sidebar.markdown("---")
st.sidebar.write("**Status:**")
if data_loaded:
    st.sidebar.success(f"‚úÖ Data loaded ({len(data)} products)")
else:
    st.sidebar.error("‚ö†Ô∏è Data not loaded")
    if data_error:
        st.sidebar.caption(f"{data_error[:50]}...")

if model_loaded:
    st.sidebar.success("‚úÖ Classification model loaded")
else:
    st.sidebar.error("‚ö†Ô∏è Model not loaded")
    if model_error:
        # Show a shortened version in sidebar, full details available in main area
        error_preview = model_error.split('\n')[0] if model_error else "Check error details"
        st.sidebar.caption(f"{error_preview[:60]}...")

# ============================================================================
# PAGE 1: HOME
# ============================================================================
if page == "üè† Home":
    st.header("üìã Dashboard Overview")
    
    st.markdown("""
    This dashboard displays visualizations and charts created from the ProteinData.ipynb analysis.
    
    ### Available Sections:
    
    **üìà Saved Charts**: View the 6 comprehensive charts saved from the notebook:
    - Basic Image Statistics
    - Color Features Analysis
    - Texture Features Analysis
    - Layout & Logo Features
    - Typography Features
    - Comprehensive Summary
    
    **üìä Interactive Charts**: Explore the data with interactive Plotly visualizations
    
    **üìã Data Explorer**: Browse and filter the dataset
    """)
    
    if data_loaded:
        st.markdown("---")
        st.header("üìÅ Dataset Information")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total Products", len(data))
        
        with col2:
            feature_count = len([c for c in data.columns if c.startswith(('mean_','std_','color_feat_','lbp_','emb_'))])
            st.metric("Features Extracted", feature_count)
        
        with col3:
            if 'Sale' in data.columns:
                avg_sales = data['Sale'].mean()
                st.metric("Average Sales", f"${avg_sales:,.0f}")
            else:
                st.metric("Average Sales", "N/A")
        
        with col4:
            st.metric("Chart Files", "6")
    else:
        st.error("‚ö†Ô∏è Data not loaded")
        if data_error:
            with st.expander("üîç View Error Details", expanded=True):
                st.markdown(data_error)
        st.info("üí° **Tip:** Run `ProteinData.ipynb` to generate `feature_table_with_metadata.csv` in the `ml_outputs/` directory.")

# ============================================================================
# PAGE 2: SAVED CHARTS
# ============================================================================
elif page == "üìà Saved Charts":
    st.header("üìà Saved Visualization Charts")
    st.markdown("These charts were generated from ProteinData.ipynb and saved as PNG files.")
    
    chart_files = {
        "1. Basic Image Statistics": "01_basic_image_statistics.png",
        "2. Color Features": "02_color_features.png",
        "3. Texture Features": "03_texture_features.png",
        "4. Layout & Logo Features": "04_layout_logo_features.png",
        "5. Typography Features": "05_typography_features.png",
        "6. Comprehensive Summary": "06_comprehensive_summary.png"
    }
    
    # Display all charts
    for chart_name, filename in chart_files.items():
        chart_path = OUTPUT_DIR / filename
        
        if chart_path.exists():
            st.subheader(chart_name)
            try:
                img = Image.open(chart_path)
                st.image(img, use_container_width=True, caption=chart_name)
            except Exception as e:
                st.error(f"Error loading {filename}: {e}")
            st.markdown("---")
        else:
            st.warning(f"Chart file not found: {filename}")
            st.info(f"Expected location: {chart_path}")
            # Debug information (only shown in development)
            if st.sidebar.checkbox("Show debug info", key=f"debug_{filename}"):
                st.code(f"PROJECT_DIR: {PROJECT_DIR}\nOUTPUT_DIR: {OUTPUT_DIR}\nChart path: {chart_path}")

# ============================================================================
# PAGE 3: INTERACTIVE CHARTS
# ============================================================================
elif page == "üìä Interactive Charts":
    st.header("üìä Interactive Data Visualizations")
    
    if not data_loaded:
        st.error("‚ö†Ô∏è Data not loaded. Cannot display interactive charts.")
        if data_error:
            with st.expander("üîç View Error Details"):
                st.markdown(data_error)
        st.info("üí° **Tip:** Run `ProteinData.ipynb` to generate `feature_table_with_metadata.csv` in the `ml_outputs/` directory.")
    else:
        # Chart type selection
        chart_type = st.selectbox(
            "Select Chart Type",
            [
                "Sales Distribution",
                "Feature vs Sales",
                "Feature Correlation Heatmap",
                "RGB Channel Analysis",
                "Feature Categories Overview"
            ]
        )
        
        st.markdown("---")
        
        if chart_type == "Sales Distribution":
            st.subheader("üìä Sales Distribution")
            if 'Sale' in data.columns:
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    bins = st.slider("Number of Bins", 5, 50, 20)
                    fig = px.histogram(
                        data, 
                        x='Sale', 
                        nbins=bins,
                        title='Distribution of Product Sales',
                        labels={'Sale': 'Sales ($)', 'count': 'Number of Products'}
                    )
                    fig.update_layout(height=500)
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    st.subheader("Statistics")
                    st.metric("Mean", f"${data['Sale'].mean():,.0f}")
                    st.metric("Median", f"${data['Sale'].median():,.0f}")
                    st.metric("Std Dev", f"${data['Sale'].std():,.0f}")
                    st.metric("Min", f"${data['Sale'].min():,.0f}")
                    st.metric("Max", f"${data['Sale'].max():,.0f}")
            else:
                st.warning("Sales column not found in data")
        
        elif chart_type == "Feature vs Sales":
            st.subheader("üìà Feature vs Sales Relationships")
            if 'Sale' in data.columns:
                feature_cols = [c for c in data.columns if c.startswith(('mean_','std_','color_feat_','lbp_','emb_','edge_density','hog_mean','aspect_ratio','white_pct','logo_score','text_pct','text_cnts'))]
                
                selected_feature = st.selectbox("Select Feature", feature_cols[:30])
                show_trendline = st.checkbox("Show Trendline", True)
                
                if selected_feature:
                    try:
                        fig = px.scatter(
                            data,
                            x=selected_feature,
                            y='Sale',
                            title=f'Sales vs {selected_feature}',
                            trendline="ols" if show_trendline else None,
                            labels={selected_feature: selected_feature, 'Sale': 'Sales ($)'}
                        )
                        fig.update_layout(height=500)
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Calculate correlation
                        corr = data[[selected_feature, 'Sale']].corr().iloc[0, 1]
                        st.metric("Correlation with Sales", f"{corr:.3f}")
                    except Exception as e:
                        st.error(f"Error creating scatter plot: {e}")
            else:
                st.warning("Sales column not found in data")
        
        elif chart_type == "Feature Correlation Heatmap":
            st.subheader("üî• Feature Correlation Heatmap")
            if 'Sale' in data.columns:
                feature_cols = [c for c in data.columns if c.startswith(('mean_','std_','color_feat_','lbp_','emb_','edge_density','hog_mean','aspect_ratio','white_pct','logo_score','text_pct','text_cnts'))]
                
                selected_features = st.multiselect(
                    "Select Features (max 15 for performance)",
                    feature_cols,
                    default=feature_cols[:10] if len(feature_cols) > 10 else feature_cols
                )
                
                if len(selected_features) > 0 and len(selected_features) <= 15:
                    try:
                        corr_matrix = data[selected_features + ['Sale']].corr()
                        
                        fig = px.imshow(
                            corr_matrix,
                            text_auto=True,
                            aspect="auto",
                            title="Feature Correlation Heatmap",
                            color_continuous_scale="RdBu"
                        )
                        fig.update_layout(height=600)
                        st.plotly_chart(fig, use_container_width=True)
                    except Exception as e:
                        st.error(f"Error creating heatmap: {e}")
            else:
                st.warning("Sales column not found in data")
        
        elif chart_type == "RGB Channel Analysis":
            st.subheader("üé® RGB Channel Analysis")
            if all(col in data.columns for col in ['mean_r', 'mean_g', 'mean_b']):
                col1, col2 = st.columns(2)
                
                with col1:
                    fig = go.Figure()
                    x_pos = np.arange(len(data))
                    width = 0.25
                    fig.add_trace(go.Bar(x=x_pos, y=data['mean_r'], name='Red', marker_color='#FF6B6B', width=width))
                    fig.add_trace(go.Bar(x=x_pos, y=data['mean_g'], name='Green', marker_color='#4ECDC4', width=width))
                    fig.add_trace(go.Bar(x=x_pos, y=data['mean_b'], name='Blue', marker_color='#45B7D1', width=width))
                    fig.update_layout(
                        title='RGB Mean Values Across Products',
                        xaxis_title='Product Index',
                        yaxis_title='Mean RGB Value (0-255)',
                        barmode='group',
                        height=400
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    fig = go.Figure()
                    fig.add_trace(go.Histogram(x=data['mean_r'], name='Red', marker_color='#FF6B6B', opacity=0.6))
                    fig.add_trace(go.Histogram(x=data['mean_g'], name='Green', marker_color='#4ECDC4', opacity=0.6))
                    fig.add_trace(go.Histogram(x=data['mean_b'], name='Blue', marker_color='#45B7D1', opacity=0.6))
                    fig.update_layout(
                        title='Distribution of RGB Mean Values',
                        xaxis_title='Mean RGB Value',
                        yaxis_title='Frequency',
                        barmode='overlay',
                        height=400
                    )
                    st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("RGB columns (mean_r, mean_g, mean_b) not found in data")
        
        elif chart_type == "Feature Categories Overview":
            st.subheader("üìä Feature Categories Overview")
            if 'Sale' in data.columns:
                categories = {
                    'Color': [c for c in data.columns if c.startswith('color_feat_') or c.startswith('mean_') or c.startswith('std_')],
                    'Texture': [c for c in data.columns if c.startswith('lbp_') or 'edge_density' in c or 'hog_mean' in c],
                    'Layout': [c for c in data.columns if 'aspect_ratio' in c or 'white_pct' in c or 'logo_score' in c],
                    'Typography': [c for c in data.columns if 'text_pct' in c or 'text_cnts' in c],
                    'Embeddings': [c for c in data.columns if c.startswith('emb_')]
                }
                
                category_corrs = {}
                for cat, features in categories.items():
                    if features:
                        try:
                            corrs = [abs(data[[f, 'Sale']].corr().iloc[0, 1]) for f in features if f in data.columns]
                            category_corrs[cat] = np.mean(corrs) if corrs else 0
                        except:
                            category_corrs[cat] = 0
                
                if len(category_corrs) > 0:
                    fig = px.bar(
                        x=list(category_corrs.keys()),
                        y=list(category_corrs.values()),
                        title='Average Feature Importance by Category',
                        labels={'x': 'Feature Category', 'y': 'Average Absolute Correlation with Sales'}
                    )
                    fig.update_layout(height=500)
                    st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("Sales column not found in data")

# ============================================================================
# PAGE 4: DATA EXPLORER
# ============================================================================
elif page == "üìã Data Explorer":
    st.header("üìã Data Explorer")
    
    if not data_loaded:
        st.error("‚ö†Ô∏è Data not loaded.")
        if data_error:
            with st.expander("üîç View Error Details"):
                st.markdown(data_error)
        st.info("üí° **Tip:** Run `ProteinData.ipynb` to generate `feature_table_with_metadata.csv` in the `ml_outputs/` directory.")
    else:
        st.markdown("Explore the dataset interactively. Filter, sort, and analyze the data.")
        
        # Filters
        st.subheader("üîç Filters")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if 'Sale' in data.columns:
                min_sales = st.number_input("Min Sales", value=float(data['Sale'].min()))
                max_sales = st.number_input("Max Sales", value=float(data['Sale'].max()))
            else:
                min_sales = max_sales = None
        
        with col2:
            if 'Product Name' in data.columns:
                product_filter = st.text_input("Filter by Product Name", "")
            else:
                product_filter = ""
        
        with col3:
            show_cols = st.multiselect(
                "Select Columns to Display",
                data.columns.tolist(),
                default=['Product Name', 'Sale'] if 'Product Name' in data.columns and 'Sale' in data.columns else data.columns[:5].tolist()
            )
        
        # Apply filters
        filtered_data = data.copy()
        
        if 'Sale' in data.columns and min_sales is not None and max_sales is not None:
            filtered_data = filtered_data[(filtered_data['Sale'] >= min_sales) & 
                                         (filtered_data['Sale'] <= max_sales)]
        
        if 'Product Name' in data.columns and product_filter:
            filtered_data = filtered_data[data['Product Name'].str.contains(product_filter, case=False, na=False)]
        
        # Display data
        st.subheader("üìä Filtered Data")
        st.dataframe(
            filtered_data[show_cols] if show_cols else filtered_data,
            use_container_width=True,
            height=400
        )
        
        # Statistics
        st.subheader("üìà Statistics")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total Rows", len(filtered_data))
        with col2:
            if 'Sale' in filtered_data.columns:
                st.metric("Avg Sales", f"${filtered_data['Sale'].mean():,.0f}")
        with col3:
            if 'Sale' in filtered_data.columns:
                st.metric("Min Sales", f"${filtered_data['Sale'].min():,.0f}")
        with col4:
            if 'Sale' in filtered_data.columns:
                st.metric("Max Sales", f"${filtered_data['Sale'].max():,.0f}")

# ============================================================================
# PAGE 5: TESTING (Image Classification)
# ============================================================================
elif page == "üß™ Testing":
    st.header("üß™ Product Label Classification Testing")
    
    if not model_loaded:
        st.error("‚ö†Ô∏è Classification model not loaded")
        if model_error:
            with st.expander("üîç View Error Details", expanded=True):
                st.markdown(model_error)
        st.info("üí° **Tip:** Run `ProteinData.ipynb` to generate the required model files (`rf_clf.pkl` and `scaler.pkl`).")
        st.info("üìù **For deployed apps:** Ensure the model files are committed to your repository and pushed to GitHub.")
    else:
        st.markdown("""
        Upload a product label image to classify whether it would have **High Sales** or **Low Sales**.
        The model will extract visual features from the image and make a prediction.
        """)
        
        # Image upload
        uploaded_file = st.file_uploader(
            "Choose a product label image (PNG, JPG, JPEG)",
            type=['png', 'jpg', 'jpeg'],
            help="Upload a product label image for classification"
        )
        
        if uploaded_file is not None:
            col1, col2 = st.columns([1, 1])
            
            with col1:
                # Display uploaded image
                image = Image.open(uploaded_file)
                st.image(image, caption="Uploaded Product Image", use_container_width=True)
            
            with col2:
                st.subheader("üîç Analysis Progress")
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    # Load and convert image
                    status_text.text("Loading image...")
                    progress_bar.progress(10)
                    img_arr = np.array(image.convert('RGB'))
                    
                    # Extract features
                    status_text.text("Extracting features...")
                    progress_bar.progress(30)
                    
                    # Feature extraction functions (simplified - no ResNet50)
                    def extract_features_simple(img_arr):
                        """Extract features from image (without ResNet50 for speed)"""
                        features = {}
                        
                        # Basic stats
                        img = Image.fromarray(img_arr.astype('uint8'))
                        stat = ImageStat.Stat(img)
                        mean = stat.mean
                        std = stat.stddev
                        features['mean_r'] = mean[0]
                        features['mean_g'] = mean[1]
                        features['mean_b'] = mean[2]
                        features['std_r'] = std[0]
                        features['std_g'] = std[1]
                        features['std_b'] = std[2]
                        
                        # Color features
                        h, w, _ = img_arr.shape
                        pixels = img_arr.reshape(-1, 3).astype(float)
                        sample_idx = np.random.choice(len(pixels), size=min(5000, len(pixels)), replace=False)
                        sample = pixels[sample_idx]
                        km = KMeans(n_clusters=3, random_state=42, n_init=10).fit(sample)
                        centers = km.cluster_centers_.astype(int)
                        labels_full = km.labels_
                        counts = np.bincount(labels_full, minlength=3) / len(labels_full)
                        hsv = rgb_to_hsv(img_arr / 255.0)
                        hvals = (hsv[:, :, 0].ravel() * 360)
                        hue_hist, _ = np.histogram(hvals, bins=12, range=(0, 360), density=True)
                        
                        color_feats = centers.flatten().tolist() + counts.tolist() + hue_hist.tolist()
                        for i, v in enumerate(color_feats):
                            features[f'color_feat_{i}'] = float(v)
                        
                        # Texture features
                        gray = rgb2gray(img_arr)
                        hog_feat, _ = hog(gray, pixels_per_cell=(16, 16), cells_per_block=(1, 1), 
                                          visualize=True, feature_vector=True)
                        edges = sobel(gray)
                        edge_density = (edges > 0.02).mean()
                        lbp = local_binary_pattern(gray, P=8, R=1.0)
                        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 2**8 + 1), density=True)
                        
                        features['edge_density'] = edge_density
                        features['hog_mean'] = np.mean(hog_feat)
                        for i, v in enumerate(hist[:16]):
                            features[f'lbp_{i}'] = float(v)
                        
                        # Layout/Logo
                        h, w, _ = img_arr.shape
                        aspect_ratio = w / h
                        gray_cv = cv2.cvtColor(img_arr.astype('uint8'), cv2.COLOR_RGB2GRAY)
                        white_pct = np.mean(gray_cv > 245)
                        edges_cv = cv2.Canny(gray_cv, 100, 200)
                        logo_score = np.sum(edges_cv) / (h * w)
                        
                        features['aspect_ratio'] = aspect_ratio
                        features['white_pct'] = white_pct
                        features['logo_score'] = logo_score
                        
                        # Typography
                        th = cv2.adaptiveThreshold(gray_cv, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                                   cv2.THRESH_BINARY_INV, 11, 2)
                        text_pct = np.mean(th > 0)
                        contours, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        text_cnts = len(contours)
                        
                        features['text_pct'] = text_pct
                        features['text_cnts'] = text_cnts
                        
                        # Embeddings (set to zero - not using ResNet50 for speed)
                        for i in range(64):
                            features[f'emb_{i}'] = 0.0
                        
                        return features
                    
                    features_dict = extract_features_simple(img_arr)
                    progress_bar.progress(70)
                    status_text.text("Preparing features for model...")
                    
                    # Prepare features in correct order
                    if data_loaded:
                        keep_cols = [c for c in data.columns if c.startswith(('mean_','std_','color_feat_','lbp_','emb_','edge_density','hog_mean','aspect_ratio','white_pct','logo_score','text_pct','text_cnts'))]
                    else:
                        # Fallback: use feature names from the dict
                        keep_cols = [k for k in features_dict.keys() if k.startswith(('mean_','std_','color_feat_','lbp_','emb_','edge_density','hog_mean','aspect_ratio','white_pct','logo_score','text_pct','text_cnts'))]
                    
                    # Create feature DataFrame
                    feature_df = pd.DataFrame([features_dict])
                    keep_cols = [c for c in keep_cols if c in feature_df.columns]
                    X_new = feature_df[keep_cols].fillna(0)
                    
                    # Scale features
                    X_scaled = scaler.transform(X_new)
                    
                    progress_bar.progress(90)
                    status_text.text("Running classification...")
                    
                    # Make prediction
                    prediction = clf_model.predict(X_scaled)[0]
                    probabilities = clf_model.predict_proba(X_scaled)[0]
                    
                    progress_bar.progress(100)
                    status_text.text("‚úÖ Analysis complete!")
                    
                    # Display results
                    st.markdown("---")
                    st.subheader("üìä Classification Results")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        sales_category = "High Sales" if prediction == 1 else "Low Sales"
                        category_color = "üü¢" if prediction == 1 else "üî¥"
                        st.metric(
                            "Predicted Category",
                            f"{category_color} {sales_category}",
                            delta=f"{probabilities[prediction]*100:.1f}% confidence"
                        )
                    
                    with col2:
                        high_prob = probabilities[1] * 100
                        st.metric(
                            "High Sales Probability",
                            f"{high_prob:.1f}%"
                        )
                    
                    with col3:
                        low_prob = probabilities[0] * 100
                        st.metric(
                            "Low Sales Probability",
                            f"{low_prob:.1f}%"
                        )
                    
                    # Probability visualization
                    st.markdown("---")
                    st.subheader("üìà Prediction Confidence")
                    
                    prob_data = pd.DataFrame({
                        'Category': ['Low Sales', 'High Sales'],
                        'Probability': [probabilities[0] * 100, probabilities[1] * 100]
                    })
                    
                    fig = px.bar(
                        prob_data,
                        x='Category',
                        y='Probability',
                        title='Sales Category Probabilities',
                        color='Category',
                        color_discrete_map={'Low Sales': '#FF6B6B', 'High Sales': '#4ECDC4'},
                        text='Probability',
                        texttemplate='%{text:.1f}%'
                    )
                    fig.update_layout(height=400, yaxis_title='Probability (%)', yaxis_range=[0, 100])
                    fig.update_traces(textposition='outside')
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Feature summary
                    st.markdown("---")
                    with st.expander("üîç View Extracted Features"):
                        st.json({k: round(v, 4) for k, v in list(features_dict.items())[:20]})
                        st.caption(f"Total features extracted: {len(features_dict)}")
                    
                except Exception as e:
                    st.error(f"Error processing image: {e}")
                    st.exception(e)
                    progress_bar.progress(0)
                    status_text.text("‚ùå Error occurred")

# ============================================================================
# FOOTER
# ============================================================================
st.sidebar.markdown("---")
st.sidebar.markdown("""
### üìö About
**Protein Sales Analysis Dashboard**

Visualization dashboard displaying charts and analysis from ProteinData.ipynb

**Author**: Mohini  
**Project**: ML PostGrad - Main Project
""")

